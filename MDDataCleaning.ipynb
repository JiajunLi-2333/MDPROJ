{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6921267",
   "metadata": {},
   "source": [
    "# The section below uses cuDF to process and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f6d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #pandas uses cpu to process data\n",
    "import cudf #cudf uses gpu to process data (RTX 5090 & RTX 4070Ti Dual Card + CUDA 12.8 + Python 3.11.12 + lastest Nvidia Driver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7da133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = cudf.read_csv(\"/home/jiajun_li/Documents/MDPROJ/Housing_Maintenance_Code_Violations_20250427.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09a5831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ViolationID', 'BuildingID', 'RegistrationID', 'BoroID', 'Borough',\n",
      "       'HouseNumber', 'LowHouseNumber', 'HighHouseNumber', 'StreetName',\n",
      "       'StreetCode', 'Postcode', 'Apartment', 'Story', 'Block', 'Lot', 'Class',\n",
      "       'InspectionDate', 'ApprovedDate', 'OriginalCertifyByDate',\n",
      "       'OriginalCorrectByDate', 'NewCertifyByDate', 'NewCorrectByDate',\n",
      "       'CertifiedDate', 'OrderNumber', 'NOVID', 'NOVDescription',\n",
      "       'NOVIssuedDate', 'CurrentStatusID', 'CurrentStatus',\n",
      "       'CurrentStatusDate', 'NovType', 'ViolationStatus', 'RentImpairing',\n",
      "       'Latitude', 'Longitude', 'CommunityBoard', 'CouncilDistrict',\n",
      "       'CensusTract', 'BIN', 'BBL', 'NTA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a227618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ViolationID', 'BuildingID', 'BoroID', 'Borough', 'HouseNumber',\n",
      "       'StreetName', 'StreetCode', 'Postcode', 'Apartment', 'Story', 'Class',\n",
      "       'InspectionDate', 'ApprovedDate', 'NOVDescription', 'CurrentStatus',\n",
      "       'CurrentStatusDate', 'NovType', 'ViolationStatus', 'RentImpairing',\n",
      "       'NTA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Drop columns that are not needed\n",
    "cols_drop = [\n",
    "    'RegistrationID',\n",
    "    'LowHouseNumber',\n",
    "    'HighHouseNumber',\n",
    "    'CertifiedDate',\n",
    "    'OrderNumber',\n",
    "    'NOVID',\n",
    "    'NOVIssuedDate',\n",
    "    'CurrentStatusID',\n",
    "    'CouncilDistrict',\n",
    "    'CensusTract',\n",
    "    'BIN',\n",
    "    'BBL',\n",
    "    'Block',\n",
    "    'Lot',\n",
    "    'OriginalCertifyByDate',\n",
    "    'OriginalCorrectByDate',\n",
    "    'NewCertifyByDate',\n",
    "    'NewCorrectByDate',\n",
    "    'Latitude',\n",
    "    'Longitude',\n",
    "    'CommunityBoard',\n",
    "]\n",
    "gdf = gdf.drop(columns = cols_drop)\n",
    "print(gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f4e61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(count := gdf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10230c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9936776, 20)\n",
      "ViolationID           int64\n",
      "BuildingID            int64\n",
      "BoroID                int64\n",
      "Borough              object\n",
      "HouseNumber          object\n",
      "StreetName           object\n",
      "StreetCode            int64\n",
      "Postcode              int64\n",
      "Apartment            object\n",
      "Story                object\n",
      "Class                object\n",
      "InspectionDate       object\n",
      "ApprovedDate         object\n",
      "NOVDescription       object\n",
      "CurrentStatus        object\n",
      "CurrentStatusDate    object\n",
      "NovType              object\n",
      "ViolationStatus      object\n",
      "RentImpairing        object\n",
      "NTA                  object\n",
      "dtype: object\n",
      "ViolationID: 9936776\n",
      "BuildingID: 230898\n",
      "BoroID: 5\n",
      "Borough: 5\n",
      "HouseNumber: 21940\n",
      "StreetName: 6039\n",
      "StreetCode: 5648\n",
      "Postcode: 220\n",
      "Apartment: 14633\n",
      "Story: 250\n",
      "Class: 4\n",
      "InspectionDate: 18101\n",
      "ApprovedDate: 20287\n",
      "NOVDescription: 6110015\n",
      "CurrentStatus: 23\n",
      "CurrentStatusDate: 10905\n",
      "NovType: 2\n",
      "ViolationStatus: 2\n",
      "RentImpairing: 2\n",
      "NTA: 203\n"
     ]
    }
   ],
   "source": [
    "print(gdf.shape)\n",
    "print(gdf.dtypes)\n",
    "\n",
    "#find the number of unique values in each column\n",
    "for col in gdf.columns:\n",
    "    print(f\"{col}: {gdf[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e947ff22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          11206\n",
      "1          11206\n",
      "2          11206\n",
      "3          11206\n",
      "4          11206\n",
      "           ...  \n",
      "9936771    11238\n",
      "9936772    11238\n",
      "9936773    11226\n",
      "9936774    11230\n",
      "9936775    11230\n",
      "Name: Postcode, Length: 9936776, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(gdf[\"Postcode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f15a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#todo data cast that is compatible with postgres\n",
    "\n",
    "\n",
    "df = gdf.copy().to_pandas()\n",
    "#Convert the data types to be compatible with PostgreSQL\n",
    "int_cols = ['ViolationID', \n",
    "            'BuildingID', \n",
    "            'BoroID',\n",
    "            'StreetCode',\n",
    "            'Postcode'\n",
    "                              ]\n",
    "for _ in int_cols:\n",
    "    df[_] = pd.to_numeric(df[_], errors = 'coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2794cca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id    230898\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[['building_id']].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86f09c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64\n",
      "0\n",
      "Int64\n",
      "8253\n"
     ]
    }
   ],
   "source": [
    "print(df['ViolationID'].dtypes)\n",
    "print(df['ViolationID'].isnull().sum())\n",
    "print(df['Postcode'].dtypes)\n",
    "print(df['Postcode'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "823feed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#todo Convert date columns to datetime\n",
    "date_cols = ['InspectionDate','ApprovedDate','CurrentStatusDate']\n",
    "for _ in date_cols:\n",
    "    df[_] = pd.to_datetime(df[_], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0637416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "0   2013-12-30\n",
      "1   2014-07-02\n",
      "2   2014-07-02\n",
      "3   2014-07-02\n",
      "4   2014-07-02\n",
      "5   2015-03-02\n",
      "6   2015-06-30\n",
      "7   2015-06-30\n",
      "8   2015-08-31\n",
      "9   2013-10-21\n",
      "Name: InspectionDate, dtype: datetime64[ns]\n",
      "datetime64[ns]\n",
      "0   2014-01-04\n",
      "1   2014-07-07\n",
      "2   2014-07-07\n",
      "3   2014-07-07\n",
      "4   2014-07-07\n",
      "5   2015-03-02\n",
      "6   2015-07-03\n",
      "7   2015-07-03\n",
      "8   2015-09-01\n",
      "9   2013-10-22\n",
      "Name: ApprovedDate, dtype: datetime64[ns]\n",
      "datetime64[ns]\n",
      "0   2014-01-25\n",
      "1   2015-08-09\n",
      "2   2015-08-09\n",
      "3   2015-08-09\n",
      "4   2015-08-09\n",
      "5   2015-03-16\n",
      "6   2016-01-06\n",
      "7   2016-01-06\n",
      "8   2015-09-02\n",
      "9   2023-09-10\n",
      "Name: CurrentStatusDate, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "for _ in date_cols:\n",
    "    print(df[_].dtypes)\n",
    "    print(df[_].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cafc3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = [\n",
    "    'Borough','HouseNumber','StreetName',\n",
    "    'Apartment','Story','Class','NOVDescription',\n",
    "    'CurrentStatus','NovType','ViolationStatus','NTA'\n",
    "]\n",
    "\n",
    "for _ in text_cols:\n",
    "     df[_] = df[_].where(df[_].notna(), pd.NA).astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73faa938",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {\n",
    "    'A': 'Non-hazardous',\n",
    "    'B': 'Hazardous',\n",
    "    'C': 'Immediately hazardous',\n",
    "    'I': 'Order to repair/vacate'\n",
    "}\n",
    "df['ClassDescription'] = df['Class'].map(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "114ffaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RentImpairing'] = (\n",
    "    df['RentImpairing']\n",
    "      .map({'Yes': True, 'No': False, 'Y': True, 'N': False})\n",
    "      .astype('boolean')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b456546f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9936776, 21)\n",
      "ViolationID                   Int64\n",
      "BuildingID                    Int64\n",
      "BoroID                        Int64\n",
      "Borough              string[python]\n",
      "HouseNumber          string[python]\n",
      "StreetName           string[python]\n",
      "StreetCode                    Int64\n",
      "Postcode                      Int64\n",
      "Apartment            string[python]\n",
      "Story                string[python]\n",
      "Class                string[python]\n",
      "InspectionDate       datetime64[ns]\n",
      "ApprovedDate         datetime64[ns]\n",
      "NOVDescription       string[python]\n",
      "CurrentStatus        string[python]\n",
      "CurrentStatusDate    datetime64[ns]\n",
      "NovType              string[python]\n",
      "ViolationStatus      string[python]\n",
      "RentImpairing               boolean\n",
      "NTA                  string[python]\n",
      "ClassDescription             object\n",
      "dtype: object\n",
      "0\n",
      "string\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "df['ClassDescription'] = df['ClassDescription'].astype('string')\n",
    "print(df['ClassDescription'].isnull().sum())\n",
    "print(df['ClassDescription'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63be9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = '5432'\n",
    "DB_NAME = \"housing_maintenance_cv\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASS = \"12345678\"\n",
    "\n",
    "def main():\n",
    "    # Connect to PostgreSQL\n",
    "    conn = psycopg.connect(\n",
    "    host = DB_HOST,\n",
    "    port = DB_PORT,\n",
    "    dbname = DB_NAME,\n",
    "    user = DB_USER,\n",
    "    password = DB_PASS)\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # For replicability\n",
    "    cur.execute(\"DROP TABLE IF EXISTS borough CASCADE;\")\n",
    "    conn.commit()\n",
    "\n",
    "    cur.execute(\"DROP TABLE IF EXISTS building CASCADE;\")\n",
    "    conn.commit()\n",
    "\n",
    "    cur.execute(\"DROP TABLE IF EXISTS nta CASCADE;\")\n",
    "    conn.commit()\n",
    "\n",
    "    cur.execute(\"DROP TABLE IF EXISTS violation CASCADE;\")\n",
    "    conn.commit()\n",
    "\n",
    "    cur.execute(\"DROP TABLE IF EXISTS violation_class CASCADE;\")\n",
    "    conn.commit()\n",
    " \n",
    "\n",
    "    borough = \"\"\" CREATE TABLE borough (\n",
    "                  borough_id BIGINT PRIMARY KEY,\n",
    "                  borough_name TEXT NOT NULL\n",
    "                  );\n",
    "              \"\"\"\n",
    "    \n",
    "    violation_class = \"\"\" CREATE TABLE violation_class (\n",
    "                          class_type VARCHAR(1) PRIMARY KEY,\n",
    "                          type_description VARCHAR(100) NOT NULL         \n",
    "                          );\n",
    "                      \"\"\"\n",
    "\n",
    "\n",
    "    nta = \"\"\" CREATE TABLE nta (\n",
    "              nta_id BIGSERIAL PRIMARY KEY,\n",
    "              nta_name TEXT NOT NULL,\n",
    "              borough_id BIGINT NOT NULL,\n",
    "              FOREIGN KEY (borough_id) REFERENCES borough(borough_id)\n",
    "              );\n",
    "          \"\"\"\n",
    "\n",
    "    building = \"\"\" CREATE TABLE building (\n",
    "                   building_id BIGINT PRIMARY KEY,\n",
    "                   house_number TEXT,\n",
    "                   street_name TEXT,\n",
    "                   street_code BIGINT,\n",
    "                   postcode BIGINT,\n",
    "                   nta_id BIGINT,\n",
    "                   borough_id BIGINT NOT NULL,\n",
    "                   FOREIGN KEY (borough_id) REFERENCES borough(borough_id),\n",
    "                   FOREIGN KEY (nta_id) REFERENCES nta(nta_id)\n",
    "                   );\n",
    "               \"\"\"\n",
    "\n",
    "    violation = \"\"\" CREATE TABLE violation (\n",
    "                    violation_id BIGINT PRIMARY KEY,\n",
    "                    inspection_date DATE,\n",
    "                    approved_date DATE,\n",
    "                    nov_description TEXT,\n",
    "                    current_status TEXT,\n",
    "                    current_status_date DATE,\n",
    "                    nov_type TEXT,\n",
    "                    violation_status TEXT,\n",
    "                    rent_impairing BOOLEAN,\n",
    "                    apartment TEXT,\n",
    "                    story TEXT,\n",
    "                    building_id BIGINT NOT NULL,\n",
    "                    class_type VARCHAR(1) NOT NULL,\n",
    "                    FOREIGN KEY (building_id) REFERENCES building(building_id),\n",
    "                    FOREIGN KEY (class_type) REFERENCES violation_class(class_type)\n",
    "                    );\n",
    "                \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    cur.execute(borough)\n",
    "    cur.execute(violation_class)\n",
    "    cur.execute(nta)\n",
    "    cur.execute(building)\n",
    "    cur.execute(violation)\n",
    "    conn.commit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f955cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = '5432'\n",
    "DB_NAME = \"housing_maintenance_cv\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASS = \"12345678\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11460083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    'ViolationID'         : 'violation_id',\n",
    "    'BuildingID'          : 'building_id',\n",
    "    'BoroID'              : 'borough_id',\n",
    "    'Class'               : 'class_type',\n",
    "    'InspectionDate'      : 'inspection_date',\n",
    "    'ApprovedDate'        : 'approved_date',\n",
    "    'CurrentStatusDate'   : 'current_status_date',\n",
    "    'NOVDescription'      : 'nov_description',\n",
    "    'NovType'             : 'nov_type',\n",
    "    'ViolationStatus'     : 'violation_status',\n",
    "    'RentImpairing'       : 'rent_impairing',\n",
    "    'NTA'                 : 'nta_name',\n",
    "    'StreetCode'          : 'street_code',\n",
    "    'Postcode'            : 'postcode',\n",
    "    'HouseNumber'         : 'house_number',\n",
    "    'StreetName'          : 'street_name',\n",
    "    'Apartment'           : 'apartment',\n",
    "    'Story'               : 'story',\n",
    "    'CurrentStatus'       : 'current_status',\n",
    "    'ClassDescription'    : 'class_description',\n",
    "    'Borough'             : 'borough_name'\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f68a2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['violation_id', 'building_id', 'borough_id', 'borough_name',\n",
      "       'house_number', 'street_name', 'street_code', 'postcode', 'apartment',\n",
      "       'story', 'class_type', 'inspection_date', 'approved_date',\n",
      "       'nov_description', 'current_status', 'current_status_date', 'nov_type',\n",
      "       'violation_status', 'rent_impairing', 'nta_name', 'class_description'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bccd90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate the borough table\n",
    "import psycopg2\n",
    "unique_boros = (\n",
    "    df[['borough_id','borough_name']]\n",
    "      .dropna(subset=['borough_id','borough_name'])\n",
    "      .drop_duplicates()\n",
    "      .values\n",
    ")\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host = DB_HOST,\n",
    "    port = DB_PORT,\n",
    "    dbname = DB_NAME,\n",
    "    user = DB_USER,\n",
    "    password = DB_PASS\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "  INSERT INTO borough (borough_id, borough_name)\n",
    "  VALUES (%s, %s)\n",
    "  ON CONFLICT (borough_id) DO NOTHING;\n",
    "\"\"\"\n",
    "cur.executemany(insert_sql, unique_boros.tolist())\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "745070c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate the nta table\n",
    "conn = psycopg2.connect(\n",
    "    host = DB_HOST,\n",
    "    port = DB_PORT,\n",
    "    dbname = DB_NAME,\n",
    "    user = DB_USER,\n",
    "    password = DB_PASS\n",
    ")\n",
    "cur = conn.cursor()\n",
    "unique_ntas = (\n",
    "    df[['nta_name','borough_id']]\n",
    "      .dropna(subset=['nta_name','borough_id'])\n",
    "      .drop_duplicates()\n",
    ")\n",
    "records = [\n",
    "    (row.nta_name, int(row.borough_id))\n",
    "    for row in unique_ntas.itertuples(index=False)\n",
    "]\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "  INSERT INTO nta (nta_name, borough_id)\n",
    "  VALUES (%s, %s)\n",
    "\"\"\"\n",
    "cur.executemany(insert_sql, records)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dacd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate the building table\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    host = DB_HOST,\n",
    "    port = DB_PORT,\n",
    "    dbname = DB_NAME,\n",
    "    user = DB_USER,\n",
    "    password = DB_PASS\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Get NTA mappings\n",
    "cur.execute(\"SELECT nta_id, nta_name FROM nta\")\n",
    "nta_map = {nta_name: nta_id for nta_id, nta_name in cur.fetchall()}\n",
    "\n",
    "# Extract all buildings with required fields\n",
    "buildings = (\n",
    "    df[['building_id', 'house_number', 'street_name', 'street_code', \n",
    "        'postcode', 'nta_name', 'borough_id']]\n",
    "    .dropna(subset=['building_id', 'borough_id'])  \n",
    "    .drop_duplicates(subset=['building_id'])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# Map NTA names to IDs, leaving NULL where no match exists\n",
    "buildings['nta_fk'] = buildings['nta_name'].map(nta_map)\n",
    "\n",
    "# Build records with nullable NTA foreign keys\n",
    "records = []\n",
    "for row in buildings.itertuples(index=False):\n",
    "    records.append((\n",
    "        int(row.building_id),\n",
    "        row.house_number,\n",
    "        row.street_name,\n",
    "        int(row.street_code) if pd.notna(row.street_code) else None,\n",
    "        int(row.postcode) if pd.notna(row.postcode) else None,\n",
    "        int(row.nta_fk) if pd.notna(row.nta_fk) else None,\n",
    "        int(row.borough_id) \n",
    "    ))\n",
    "\n",
    "# Insert buildings with ON CONFLICT handling\n",
    "insert_sql = \"\"\"\n",
    "  INSERT INTO building (\n",
    "    building_id,\n",
    "    house_number,\n",
    "    street_name,\n",
    "    street_code,\n",
    "    postcode,\n",
    "    nta_id,\n",
    "    borough_id\n",
    "  ) VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "  ON CONFLICT (building_id) DO NOTHING;\n",
    "\"\"\"\n",
    "cur.executemany(insert_sql, records)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ed53525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate the violation_class table\n",
    "conn = psycopg2.connect(\n",
    "    host = DB_HOST,\n",
    "    port = DB_PORT,\n",
    "    dbname = DB_NAME,\n",
    "    user = DB_USER,\n",
    "    password = DB_PASS\n",
    ")\n",
    "cur = conn.cursor()\n",
    "unique_classes = (\n",
    "    df[['class_type','class_description']]\n",
    "      .dropna(subset=['class_type','class_description'])\n",
    "      .drop_duplicates()\n",
    ")\n",
    "\n",
    "records = [\n",
    "    (row.class_type, row.class_description)\n",
    "    for row in unique_classes.itertuples(index=False)\n",
    "]\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "  INSERT INTO violation_class (class_type, type_description)\n",
    "  VALUES (%s, %s)\n",
    "  ON CONFLICT (class_type) DO NOTHING;\n",
    "\"\"\"\n",
    "cur.executemany(insert_sql, records)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "559c8425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate the violation_class table\n",
    "conn = psycopg2.connect(\n",
    "    host = DB_HOST,\n",
    "    port = DB_PORT,\n",
    "    dbname = DB_NAME,\n",
    "    user = DB_USER,\n",
    "    password = DB_PASS\n",
    ")\n",
    "cur = conn.cursor()\n",
    "unique_classes = (\n",
    "    df[['class_type','class_description']]\n",
    "      .dropna(subset=['class_type','class_description'])\n",
    "      .drop_duplicates()\n",
    ")\n",
    "\n",
    "records = [\n",
    "    (row.class_type, row.class_description)\n",
    "    for row in unique_classes.itertuples(index=False)\n",
    "]\n",
    "\n",
    "# Insert with conflict handling\n",
    "insert_sql = \"\"\"\n",
    "  INSERT INTO violation_class (class_type, type_description)\n",
    "  VALUES (%s, %s)\n",
    "  ON CONFLICT (class_type) DO NOTHING;\n",
    "\"\"\"\n",
    "cur.executemany(insert_sql, records)\n",
    "conn.commit()\n",
    "\n",
    "# Build records with nullable NTA foreign keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "731fdda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_type    0\n",
      "dtype: int64\n",
      "building_id    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#populate the violation table\n",
    "print(df[['class_type']].isnull().sum())\n",
    "print(df[['building_id']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9458175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "violation = \"\"\" CREATE TABLE violation (\n",
    "                    violation_id BIGINT PRIMARY KEY,\n",
    "                    inspection_date DATE,\n",
    "                    approved_date DATE,\n",
    "                    nov_description TEXT,\n",
    "                    current_status TEXT,\n",
    "                    current_status_date DATE,\n",
    "                    nov_type TEXT,\n",
    "                    violation_status TEXT,\n",
    "                    rent_impairing BOOLEAN,\n",
    "                    apartment TEXT,\n",
    "                    story TEXT,\n",
    "                    building_id BIGINT NOT NULL,\n",
    "                    class_type VARCHAR(1) NOT NULL,\n",
    "                    FOREIGN KEY (building_id) REFERENCES building(building_id),\n",
    "                    FOREIGN KEY (class_type) REFERENCES violation_class(class_type)\n",
    "                    );\n",
    "                \"\"\"\n",
    "cur.execute(violation)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4380fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total violations: 9936776\n",
      "Valid violations for insert: 9936776\n",
      "Batch 1/994: Inserted 10,000 rows (0.1%) - Rate: 22080 rows/sec\n",
      "Batch 11/994: Inserted 110,000 rows (1.1%) - Rate: 32338 rows/sec\n",
      "Batch 21/994: Inserted 210,000 rows (2.1%) - Rate: 32042 rows/sec\n",
      "Batch 31/994: Inserted 310,000 rows (3.1%) - Rate: 32580 rows/sec\n",
      "Batch 41/994: Inserted 410,000 rows (4.1%) - Rate: 32473 rows/sec\n",
      "Batch 51/994: Inserted 510,000 rows (5.1%) - Rate: 30816 rows/sec\n",
      "Batch 61/994: Inserted 610,000 rows (6.1%) - Rate: 31139 rows/sec\n",
      "Batch 71/994: Inserted 710,000 rows (7.1%) - Rate: 31446 rows/sec\n",
      "Batch 81/994: Inserted 810,000 rows (8.2%) - Rate: 31686 rows/sec\n",
      "Batch 91/994: Inserted 910,000 rows (9.2%) - Rate: 31880 rows/sec\n",
      "Batch 101/994: Inserted 1,010,000 rows (10.2%) - Rate: 32045 rows/sec\n",
      "Batch 111/994: Inserted 1,110,000 rows (11.2%) - Rate: 32073 rows/sec\n",
      "Batch 121/994: Inserted 1,210,000 rows (12.2%) - Rate: 32152 rows/sec\n",
      "Batch 131/994: Inserted 1,310,000 rows (13.2%) - Rate: 32171 rows/sec\n",
      "Batch 141/994: Inserted 1,410,000 rows (14.2%) - Rate: 32153 rows/sec\n",
      "Batch 151/994: Inserted 1,510,000 rows (15.2%) - Rate: 31536 rows/sec\n",
      "Batch 161/994: Inserted 1,610,000 rows (16.2%) - Rate: 31499 rows/sec\n",
      "Batch 171/994: Inserted 1,710,000 rows (17.2%) - Rate: 31541 rows/sec\n",
      "Batch 181/994: Inserted 1,810,000 rows (18.2%) - Rate: 31638 rows/sec\n",
      "Batch 191/994: Inserted 1,910,000 rows (19.2%) - Rate: 31698 rows/sec\n",
      "Batch 201/994: Inserted 2,010,000 rows (20.2%) - Rate: 31779 rows/sec\n",
      "Batch 211/994: Inserted 2,110,000 rows (21.2%) - Rate: 31858 rows/sec\n",
      "Batch 221/994: Inserted 2,210,000 rows (22.2%) - Rate: 31927 rows/sec\n",
      "Batch 231/994: Inserted 2,310,000 rows (23.2%) - Rate: 31991 rows/sec\n",
      "Batch 241/994: Inserted 2,410,000 rows (24.3%) - Rate: 32070 rows/sec\n",
      "Batch 251/994: Inserted 2,510,000 rows (25.3%) - Rate: 32145 rows/sec\n",
      "Batch 261/994: Inserted 2,610,000 rows (26.3%) - Rate: 31841 rows/sec\n",
      "Batch 271/994: Inserted 2,710,000 rows (27.3%) - Rate: 31917 rows/sec\n",
      "Batch 281/994: Inserted 2,810,000 rows (28.3%) - Rate: 31959 rows/sec\n",
      "Batch 291/994: Inserted 2,910,000 rows (29.3%) - Rate: 32007 rows/sec\n",
      "Batch 301/994: Inserted 3,010,000 rows (30.3%) - Rate: 32068 rows/sec\n",
      "Batch 311/994: Inserted 3,110,000 rows (31.3%) - Rate: 32085 rows/sec\n",
      "Batch 321/994: Inserted 3,210,000 rows (32.3%) - Rate: 32115 rows/sec\n",
      "Batch 331/994: Inserted 3,310,000 rows (33.3%) - Rate: 32139 rows/sec\n",
      "Batch 341/994: Inserted 3,410,000 rows (34.3%) - Rate: 32183 rows/sec\n",
      "Batch 351/994: Inserted 3,510,000 rows (35.3%) - Rate: 32229 rows/sec\n",
      "Batch 361/994: Inserted 3,610,000 rows (36.3%) - Rate: 32282 rows/sec\n",
      "Batch 371/994: Inserted 3,710,000 rows (37.3%) - Rate: 32110 rows/sec\n",
      "Batch 381/994: Inserted 3,810,000 rows (38.3%) - Rate: 32144 rows/sec\n",
      "Batch 391/994: Inserted 3,910,000 rows (39.3%) - Rate: 32183 rows/sec\n",
      "Batch 401/994: Inserted 4,010,000 rows (40.4%) - Rate: 32209 rows/sec\n",
      "Batch 411/994: Inserted 4,110,000 rows (41.4%) - Rate: 32233 rows/sec\n",
      "Batch 421/994: Inserted 4,210,000 rows (42.4%) - Rate: 32255 rows/sec\n",
      "Batch 431/994: Inserted 4,310,000 rows (43.4%) - Rate: 32275 rows/sec\n",
      "Batch 441/994: Inserted 4,410,000 rows (44.4%) - Rate: 32303 rows/sec\n",
      "Batch 451/994: Inserted 4,510,000 rows (45.4%) - Rate: 32344 rows/sec\n",
      "Batch 461/994: Inserted 4,610,000 rows (46.4%) - Rate: 32367 rows/sec\n",
      "Batch 471/994: Inserted 4,710,000 rows (47.4%) - Rate: 32220 rows/sec\n",
      "Batch 481/994: Inserted 4,810,000 rows (48.4%) - Rate: 32239 rows/sec\n",
      "Batch 491/994: Inserted 4,910,000 rows (49.4%) - Rate: 32274 rows/sec\n",
      "Batch 501/994: Inserted 5,010,000 rows (50.4%) - Rate: 32309 rows/sec\n",
      "Batch 511/994: Inserted 5,110,000 rows (51.4%) - Rate: 32339 rows/sec\n",
      "Batch 521/994: Inserted 5,210,000 rows (52.4%) - Rate: 32365 rows/sec\n",
      "Batch 531/994: Inserted 5,310,000 rows (53.4%) - Rate: 32374 rows/sec\n",
      "Batch 541/994: Inserted 5,410,000 rows (54.4%) - Rate: 32408 rows/sec\n",
      "Batch 551/994: Inserted 5,510,000 rows (55.5%) - Rate: 32427 rows/sec\n",
      "Batch 561/994: Inserted 5,610,000 rows (56.5%) - Rate: 32454 rows/sec\n",
      "Batch 571/994: Inserted 5,710,000 rows (57.5%) - Rate: 32485 rows/sec\n",
      "Batch 581/994: Inserted 5,810,000 rows (58.5%) - Rate: 32368 rows/sec\n",
      "Batch 591/994: Inserted 5,910,000 rows (59.5%) - Rate: 32397 rows/sec\n",
      "Batch 601/994: Inserted 6,010,000 rows (60.5%) - Rate: 32435 rows/sec\n",
      "Batch 611/994: Inserted 6,110,000 rows (61.5%) - Rate: 32460 rows/sec\n",
      "Batch 621/994: Inserted 6,210,000 rows (62.5%) - Rate: 32474 rows/sec\n",
      "Batch 631/994: Inserted 6,310,000 rows (63.5%) - Rate: 32493 rows/sec\n",
      "Batch 641/994: Inserted 6,410,000 rows (64.5%) - Rate: 32519 rows/sec\n",
      "Batch 651/994: Inserted 6,510,000 rows (65.5%) - Rate: 32551 rows/sec\n",
      "Batch 661/994: Inserted 6,610,000 rows (66.5%) - Rate: 32565 rows/sec\n",
      "Batch 671/994: Inserted 6,710,000 rows (67.5%) - Rate: 32578 rows/sec\n",
      "Batch 681/994: Inserted 6,810,000 rows (68.5%) - Rate: 32590 rows/sec\n",
      "Batch 691/994: Inserted 6,910,000 rows (69.5%) - Rate: 32485 rows/sec\n",
      "Batch 701/994: Inserted 7,010,000 rows (70.5%) - Rate: 32505 rows/sec\n",
      "Batch 711/994: Inserted 7,110,000 rows (71.6%) - Rate: 32531 rows/sec\n",
      "Batch 721/994: Inserted 7,210,000 rows (72.6%) - Rate: 32533 rows/sec\n",
      "Batch 731/994: Inserted 7,310,000 rows (73.6%) - Rate: 32550 rows/sec\n",
      "Batch 741/994: Inserted 7,410,000 rows (74.6%) - Rate: 32566 rows/sec\n",
      "Batch 751/994: Inserted 7,510,000 rows (75.6%) - Rate: 32579 rows/sec\n",
      "Batch 761/994: Inserted 7,610,000 rows (76.6%) - Rate: 32598 rows/sec\n",
      "Batch 771/994: Inserted 7,710,000 rows (77.6%) - Rate: 32614 rows/sec\n",
      "Batch 781/994: Inserted 7,810,000 rows (78.6%) - Rate: 32617 rows/sec\n",
      "Batch 791/994: Inserted 7,910,000 rows (79.6%) - Rate: 32637 rows/sec\n",
      "Batch 801/994: Inserted 8,010,000 rows (80.6%) - Rate: 32552 rows/sec\n",
      "Batch 811/994: Inserted 8,110,000 rows (81.6%) - Rate: 32572 rows/sec\n",
      "Batch 821/994: Inserted 8,210,000 rows (82.6%) - Rate: 32569 rows/sec\n",
      "Batch 831/994: Inserted 8,310,000 rows (83.6%) - Rate: 32572 rows/sec\n",
      "Batch 841/994: Inserted 8,410,000 rows (84.6%) - Rate: 32571 rows/sec\n",
      "Batch 851/994: Inserted 8,510,000 rows (85.6%) - Rate: 32577 rows/sec\n",
      "Batch 861/994: Inserted 8,610,000 rows (86.6%) - Rate: 32593 rows/sec\n",
      "Batch 871/994: Inserted 8,710,000 rows (87.7%) - Rate: 32606 rows/sec\n",
      "Batch 881/994: Inserted 8,810,000 rows (88.7%) - Rate: 32617 rows/sec\n",
      "Batch 891/994: Inserted 8,910,000 rows (89.7%) - Rate: 32626 rows/sec\n",
      "Batch 901/994: Inserted 9,010,000 rows (90.7%) - Rate: 32640 rows/sec\n",
      "Batch 911/994: Inserted 9,110,000 rows (91.7%) - Rate: 32547 rows/sec\n",
      "Batch 921/994: Inserted 9,210,000 rows (92.7%) - Rate: 32567 rows/sec\n",
      "Batch 931/994: Inserted 9,310,000 rows (93.7%) - Rate: 32582 rows/sec\n",
      "Batch 941/994: Inserted 9,410,000 rows (94.7%) - Rate: 32593 rows/sec\n",
      "Batch 951/994: Inserted 9,510,000 rows (95.7%) - Rate: 32604 rows/sec\n",
      "Batch 961/994: Inserted 9,610,000 rows (96.7%) - Rate: 32602 rows/sec\n",
      "Batch 971/994: Inserted 9,710,000 rows (97.7%) - Rate: 32603 rows/sec\n",
      "Batch 981/994: Inserted 9,810,000 rows (98.7%) - Rate: 32601 rows/sec\n",
      "Batch 991/994: Inserted 9,910,000 rows (99.7%) - Rate: 32598 rows/sec\n",
      "Batch 994/994: Inserted 9,936,776 rows (100.0%) - Rate: 32602 rows/sec\n",
      "\n",
      "Completed: 9,936,776 rows inserted in 304.8 seconds\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "import time\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host = DB_HOST,\n",
    "    port = DB_PORT,\n",
    "    dbname = DB_NAME,\n",
    "    user = DB_USER,\n",
    "    password = DB_PASS\n",
    ")\n",
    "conn.autocommit = False\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Get existing building IDs for faster lookup (in-memory)\n",
    "cur.execute(\"SELECT building_id FROM building\")\n",
    "valid_building_ids = set([row[0] for row in cur.fetchall()])\n",
    "\n",
    "# Get valid class types\n",
    "cur.execute(\"SELECT class_type FROM violation_class\")\n",
    "valid_class_types = set([row[0] for row in cur.fetchall()])\n",
    "\n",
    "# Filter violations that have valid foreign keys\n",
    "valid_violations = df[\n",
    "    df['building_id'].isin(valid_building_ids) & \n",
    "    df['class_type'].isin(valid_class_types) &\n",
    "    df['violation_id'].notna()\n",
    "].copy()\n",
    "\n",
    "print(f\"Total violations: {len(df)}\")\n",
    "print(f\"Valid violations for insert: {len(valid_violations)}\")\n",
    "\n",
    "# Configure batch size\n",
    "BATCH_SIZE = 10000\n",
    "total_batches = (len(valid_violations) // BATCH_SIZE) + 1\n",
    "\n",
    "# Prepare SQL statement\n",
    "insert_sql = \"\"\"\n",
    "    INSERT INTO violation (\n",
    "        violation_id, inspection_date, approved_date, nov_description,\n",
    "        current_status, current_status_date, nov_type, violation_status,\n",
    "        rent_impairing, apartment, story, building_id, class_type\n",
    "    ) VALUES %s\n",
    "    ON CONFLICT (violation_id) DO NOTHING;\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "rows_inserted = 0\n",
    "\n",
    "try:\n",
    "    # Process in batches\n",
    "    for batch_num in range(total_batches):\n",
    "        start_idx = batch_num * BATCH_SIZE\n",
    "        end_idx = min(start_idx + BATCH_SIZE, len(valid_violations))\n",
    "        \n",
    "        if start_idx >= end_idx:\n",
    "            break\n",
    "            \n",
    "        batch = valid_violations.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Convert to list of tuples for insertion\n",
    "        records = []\n",
    "        for row in batch.itertuples(index=False):\n",
    "            records.append((\n",
    "                int(row.violation_id),\n",
    "                #replace NaN and NAT\n",
    "                None if pd.isna(row.inspection_date) else row.inspection_date,\n",
    "                None if pd.isna(row.approved_date) else row.approved_date,\n",
    "                None if pd.isna(row.nov_description) else row.nov_description,\n",
    "                None if pd.isna(row.current_status) else row.current_status,\n",
    "                None if pd.isna(row.current_status_date) else row.current_status_date,\n",
    "                None if pd.isna(row.nov_type) else row.nov_type,\n",
    "                None if pd.isna(row.violation_status) else row.violation_status,\n",
    "                bool(row.rent_impairing) if pd.notna(row.rent_impairing) else None,\n",
    "                None if pd.isna(row.apartment) else row.apartment,\n",
    "                None if pd.isna(row.story) else row.story,\n",
    "                int(row.building_id),\n",
    "                row.class_type\n",
    "            ))\n",
    "        \n",
    "        # Use execute_values for faster batch insert\n",
    "        execute_values(cur, insert_sql, records, template=None, page_size=BATCH_SIZE)\n",
    "        \n",
    "        # Commit each batch\n",
    "        conn.commit()\n",
    "        \n",
    "        rows_inserted += len(records)\n",
    "        elapsed = time.time() - start_time\n",
    "        rate = rows_inserted / elapsed if elapsed > 0 else 0\n",
    "        \n",
    "        # Progress update every 10 batches or at the end\n",
    "        if batch_num % 10 == 0 or batch_num == total_batches - 1:\n",
    "            print(f\"Batch {batch_num+1}/{total_batches}: Inserted {rows_inserted:,} rows \" \n",
    "                  f\"({rows_inserted/len(valid_violations)*100:.1f}%) - \"\n",
    "                  f\"Rate: {rate:.0f} rows/sec\")\n",
    "    \n",
    "    print(f\"\\nCompleted: {rows_inserted:,} rows inserted in {time.time() - start_time:.1f} seconds\")\n",
    "\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12273bf9",
   "metadata": {},
   "source": [
    "## Query Buildings by Borough and Neighborhood\n",
    "This section shows how to look up `borough_id` and `nta_id` from their tables and then retrieve matching records from the `building` table based on user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16902ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "# Example user inputs; replace with dynamic values as needed\n",
    "input_borough = 'Bronx'\n",
    "input_neighborhood = 'Fordham'\n",
    "\n",
    "# Connect to the database\n",
    "conn = psycopg2.connect(host=DB_HOST, port=DB_PORT, dbname=DB_NAME, user=DB_USER, password=DB_PASS)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Retrieve borough_id\n",
    "cur.execute('SELECT borough_id FROM borough WHERE borough_name = %s', (input_borough,))\n",
    "row = cur.fetchone()\n",
    "borough_id = row[0] if row else None\n",
    "\n",
    "# Retrieve nta_id filtering by borough\n",
    "cur.execute('SELECT nta_id FROM nta WHERE nta_name = %s AND borough_id = %s', (input_neighborhood, borough_id))\n",
    "row = cur.fetchone()\n",
    "nta_id = row[0] if row else None\n",
    "\n",
    "# Build and execute building query\n",
    "query = 'SELECT * FROM building WHERE 1=1'\n",
    "params = []\n",
    "if borough_id is not None:\n",
    "    query += ' AND borough_id = %s'; params.append(borough_id)\n",
    "if nta_id is not None:\n",
    "    query += ' AND nta_id = %s'; params.append(nta_id)\n",
    "\n",
    "cur.execute(query, tuple(params))\n",
    "buildings = cur.fetchall()\n",
    "print('Matched Buildings:')\n",
    "for b in buildings: print(b)\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
